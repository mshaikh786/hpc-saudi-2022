{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7cca780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896c4d39-0b0c-4d23-acc6-c200a3314523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ab3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=1\n",
    "gpus=2\n",
    "nr=0\n",
    "master_addr='127.0.0.1'\n",
    "master_port='9992'\n",
    "\n",
    "batch_size=16\n",
    "epochs=2\n",
    "\n",
    "world_size = gpus * nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da13a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR']=master_addr\n",
    "os.environ['MASTER_PORT']=master_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "764ab886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84c21bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gpu, nr,gpus,world_size,epochs,batch_size):\n",
    "    rank = nr * gpus + gpu\n",
    "    dist.init_process_group(backend='nccl', \n",
    "            #init_method=\"env://\",\n",
    "            world_size=world_size, rank=rank)\n",
    "    torch.manual_seed(0)\n",
    "    model = ConvNet()\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model.cuda(gpu)\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n",
    "    # Wrap the model\n",
    "    model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu])\n",
    "    # Data loading code\n",
    "    train_dataset = torchvision.datasets.MNIST(root='home/mohsin/hpc-saudi-2022/kubeflow-demo/data',\n",
    "                                               train=True,\n",
    "                                               transform=transforms.ToTensor(),\n",
    "                                               download=True)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,\n",
    "                                                                    num_replicas=world_size,\n",
    "                                                                    rank=rank)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True,\n",
    "                                               sampler=train_sampler)\n",
    "\n",
    "    start = datetime.now()\n",
    "    total_step = len(train_loader)\n",
    "    print(\"Starting the training loop\")\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 100 == 0 and gpu == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, epochs, i + 1, total_step,\n",
    "\n",
    "        loss.item()))\n",
    "    if gpu == 0:\n",
    "        print(\"Training complete in: \" + str(datetime.now() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e327d9-711c-457e-a71d-47c394063ab4",
   "metadata": {},
   "source": [
    "torch.multiprocessing.set_start_method('fork')\n",
    "processes = [mp.Process(target=train, args=(i,nr,gpus,world_size,epochs,batch_size)) for i in range(world_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3108c-d141-4c04-8e2d-616f6dbe2407",
   "metadata": {},
   "source": [
    "for p in processes:\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b35b20-cc31-4374-a973-6fc36ff0746f",
   "metadata": {},
   "source": [
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee12934-d400-481c-8808-074ae6bda5ea",
   "metadata": {},
   "source": [
    "mp.spawn(train, args=(nr,gpus,world_size,epochs,batch_size),nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbb02676-70b0-4b41-9ad5-c6206f52b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (0.70.13)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /opt/conda/lib/python3.8/site-packages (from multiprocess) (0.3.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a39ff5b-7e9a-4b30-adbb-6b414bfa9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31eba0d2-3ee1-4325-a6d1-f7d28a5dd65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 263522689.78it/s]\n",
      "100%|██████████| 9912422/9912422 [00:00<00:00, 118599004.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/train-images-idx3-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/rawExtracting home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/train-images-idx3-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw\n",
      "\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 176582644.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/train-labels-idx1-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 894913483.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/t10k-images-idx3-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw\n",
      "Using downloaded and verified file: home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/train-labels-idx1-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/t10k-images-idx3-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 32845739.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 25299507.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to home/mohsin/hpc-saudi-2022/kubeflow-demo/data/MNIST/raw\n",
      "\n",
      "Starting the training loop\n",
      "Starting the training loop\n",
      "Epoch [1/2], Step [100/1875], Loss: 2.1635\n",
      "Epoch [1/2], Step [200/1875], Loss: 1.9377\n",
      "Epoch [1/2], Step [300/1875], Loss: 1.9032\n",
      "Epoch [1/2], Step [400/1875], Loss: 1.8220\n",
      "Epoch [1/2], Step [500/1875], Loss: 1.7550\n",
      "Epoch [1/2], Step [600/1875], Loss: 1.4583\n",
      "Epoch [1/2], Step [700/1875], Loss: 1.5107\n",
      "Epoch [1/2], Step [800/1875], Loss: 1.4549\n",
      "Epoch [1/2], Step [900/1875], Loss: 1.3747\n",
      "Epoch [1/2], Step [1000/1875], Loss: 1.2107\n",
      "Epoch [1/2], Step [1100/1875], Loss: 1.2325\n",
      "Epoch [1/2], Step [1200/1875], Loss: 1.1732\n",
      "Epoch [1/2], Step [1300/1875], Loss: 1.1506\n",
      "Epoch [1/2], Step [1400/1875], Loss: 0.8159\n",
      "Epoch [1/2], Step [1500/1875], Loss: 1.2118\n",
      "Epoch [1/2], Step [1600/1875], Loss: 0.9696\n",
      "Epoch [1/2], Step [1700/1875], Loss: 0.7535\n",
      "Epoch [1/2], Step [1800/1875], Loss: 0.7122\n",
      "Epoch [2/2], Step [100/1875], Loss: 0.9828\n",
      "Epoch [2/2], Step [200/1875], Loss: 0.7861\n",
      "Epoch [2/2], Step [300/1875], Loss: 0.7053\n",
      "Epoch [2/2], Step [400/1875], Loss: 0.7449\n",
      "Epoch [2/2], Step [500/1875], Loss: 0.9888\n",
      "Epoch [2/2], Step [600/1875], Loss: 0.5555\n",
      "Epoch [2/2], Step [700/1875], Loss: 0.6797\n",
      "Epoch [2/2], Step [800/1875], Loss: 0.7151\n",
      "Epoch [2/2], Step [900/1875], Loss: 0.7682\n",
      "Epoch [2/2], Step [1000/1875], Loss: 0.6744\n",
      "Epoch [2/2], Step [1100/1875], Loss: 0.7104\n",
      "Epoch [2/2], Step [1200/1875], Loss: 0.5775\n",
      "Epoch [2/2], Step [1300/1875], Loss: 0.6259\n",
      "Epoch [2/2], Step [1400/1875], Loss: 0.4158\n",
      "Epoch [2/2], Step [1500/1875], Loss: 0.7702\n",
      "Epoch [2/2], Step [1600/1875], Loss: 0.5933\n",
      "Epoch [2/2], Step [1700/1875], Loss: 0.3802\n",
      "Epoch [2/2], Step [1800/1875], Loss: 0.4071\n",
      "Training complete in: 0:00:20.804360\n",
      "[None, None]\n"
     ]
    }
   ],
   "source": [
    "with multiprocess.Pool(gpus) as pool:\n",
    "    print(pool.starmap(train, [(i,nr,gpus,world_size,epochs,batch_size) for i in range(gpus)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e05104-d4f4-42a6-8a7c-0101072c9883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
